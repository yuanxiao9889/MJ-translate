import requests
import semver
import json
import os
import zipfile
import shutil
import tempfile
from pathlib import Path
from services import __version__ as current_version

class UpdateManager:
    def __init__(self):
        self.config = self._load_config()
        self.current_version = current_version
        self.offline_mode = False
        self.manual_download_info = None

    def _load_config(self):
        config_path = os.path.join(os.path.dirname(__file__), '..', 'config.json')
        try:
            with open(config_path, 'r') as f:
                return json.load(f)
        except (FileNotFoundError, json.JSONDecodeError):
            return {}

    def check_for_updates(self):
        """Checks for new releases on GitHub."""
        repo_owner = self.config.get('github_owner')
        repo_name = self.config.get('github_repo')
        if not repo_owner or not repo_name:
            print("GitHub repository owner or name not configured.")
            return None, None

        api_url = f"https://api.github.com/repos/{repo_owner}/{repo_name}/releases/latest"
        
        # é…ç½®è¯·æ±‚å‚æ•°ï¼Œç¦ç”¨ä»£ç†å¹¶è®¾ç½®è¶…æ—¶
        session = requests.Session()
        session.trust_env = False  # ç¦ç”¨ç¯å¢ƒå˜é‡ä¸­çš„ä»£ç†è®¾ç½®
        session.proxies = {}  # æ¸…ç©ºä»£ç†è®¾ç½®
        
        headers = {
            'User-Agent': 'MJ-Translator-Update-Checker/1.0',
            'Accept': 'application/vnd.github.v3+json'
        }
        
        # é‡è¯•æœºåˆ¶
        max_retries = 3
        for attempt in range(max_retries):
            try:
                print(f"æ­£åœ¨æ£€æŸ¥æ›´æ–°... (å°è¯• {attempt + 1}/{max_retries})")
                response = session.get(
                    api_url, 
                    headers=headers,
                    timeout=30,  # 30ç§’è¶…æ—¶
                    proxies={}  # ç¡®ä¿ä¸ä½¿ç”¨ä»£ç†
                )
                response.raise_for_status()
                latest_release = response.json()
                latest_version = latest_release['tag_name'].lstrip('v')
                release_notes = latest_release['body']
                print(f"æˆåŠŸè·å–æœ€æ–°ç‰ˆæœ¬ä¿¡æ¯: {latest_version}")
                
                # ä¿å­˜å‘å¸ƒä¿¡æ¯ä¾›ç¦»çº¿ä½¿ç”¨
                self._save_release_info(latest_release)
                
                return latest_version, release_notes
                
            except requests.exceptions.ProxyError as e:
                print(f"ä»£ç†è¿æ¥é”™è¯¯ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    print("æ­£åœ¨é‡è¯•...")
                    continue
                else:
                    print("æ‰€æœ‰é‡è¯•å‡å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¦ç”¨ä»£ç†")
                    
            except requests.exceptions.Timeout as e:
                print(f"è¯·æ±‚è¶…æ—¶ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    print("æ­£åœ¨é‡è¯•...")
                    continue
                    
            except requests.exceptions.ConnectionError as e:
                print(f"è¿æ¥é”™è¯¯ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    print("æ­£åœ¨é‡è¯•...")
                    continue
                    
            except requests.exceptions.RequestException as e:
                print(f"è¯·æ±‚é”™è¯¯ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    print("æ­£åœ¨é‡è¯•...")
                    continue
                    
        print("æ— æ³•è¿æ¥åˆ°GitHub APIï¼Œå°è¯•ä½¿ç”¨ç¦»çº¿æ¨¡å¼")
        return self._check_offline_update()

    def is_new_version_available(self, latest_version):
        """Compares the latest version with the current version."""
        if not latest_version:
            return False
        
        try:
            # å°è¯•ä½¿ç”¨è¯­ä¹‰åŒ–ç‰ˆæœ¬æ¯”è¾ƒ
            return semver.compare(latest_version, self.current_version) > 0
        except ValueError:
            # å¦‚æœç‰ˆæœ¬å·ä¸ç¬¦åˆè¯­ä¹‰åŒ–ç‰ˆæœ¬è§„èŒƒï¼Œä½¿ç”¨å­—ç¬¦ä¸²æ¯”è¾ƒ
            print(f"è­¦å‘Š: ç‰ˆæœ¬å· '{latest_version}' ä¸ç¬¦åˆè¯­ä¹‰åŒ–ç‰ˆæœ¬è§„èŒƒï¼Œä½¿ç”¨å­—ç¬¦ä¸²æ¯”è¾ƒ")
            # ç®€å•çš„å­—ç¬¦ä¸²æ¯”è¾ƒï¼Œå¦‚æœä¸åŒå°±è®¤ä¸ºæœ‰æ–°ç‰ˆæœ¬
            return latest_version != self.current_version

    def _get_download_url_with_fallback(self, latest_release):
        """è·å–ä¸‹è½½URLï¼Œä½¿ç”¨å¤šä¸ªå¤‡ç”¨æ–¹æ¡ˆ"""
        repo_owner = self.config.get('github_owner')
        repo_name = self.config.get('github_repo')
        tag_name = latest_release.get('tag_name', 'latest')
        
        # æ–¹æ¡ˆ1: ç”¨æˆ·ä¸Šä¼ çš„assets
        assets = latest_release.get('assets', [])
        for asset in assets:
            if asset['name'].endswith('.zip'):
                return asset['browser_download_url'], asset['name'], asset.get('size', 0)
        
        # æ–¹æ¡ˆ2: åªä½¿ç”¨å¯ç”¨çš„github.comåŸŸåï¼ˆé¿å…codeload.github.com DNSè§£æé—®é¢˜ï¼‰
        download_urls = [
            f"https://github.com/{repo_owner}/{repo_name}/archive/refs/tags/{tag_name}.zip"
        ]
        
        file_name = f"{repo_name}-{tag_name}.zip"
        
        # æµ‹è¯•æ¯ä¸ªURLçš„å¯è¾¾æ€§
        session = requests.Session()
        session.trust_env = False
        session.proxies = {}
        headers = {
            'User-Agent': 'MJ-Translator-Update-Checker/1.0'
        }
        
        for url in download_urls:
            try:
                print(f"æµ‹è¯•ä¸‹è½½URL: {url}")
                # åªå‘é€HEADè¯·æ±‚æµ‹è¯•è¿æ¥
                response = session.head(url, headers=headers, timeout=10)
                if response.status_code in [200, 302]:
                    print(f"âœ“ URLå¯ç”¨: {url}")
                    return url, file_name, 0
            except Exception as e:
                print(f"âœ— URLä¸å¯ç”¨: {url} - {e}")
                continue
        
        raise Exception("æ‰€æœ‰ä¸‹è½½URLéƒ½ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
    
    def _download_with_retry(self, url, file_path, headers=None, max_retries=3):
        """å¸¦é‡è¯•æœºåˆ¶çš„ä¸‹è½½"""
        import time
        session = requests.Session()
        session.trust_env = False
        session.proxies = {}
        
        if not headers:
            headers = {
                'User-Agent': 'MJ-Translator-Update-Checker/1.0',
                'Accept': 'application/octet-stream'
            }
        
        for attempt in range(max_retries):
            try:
                print(f"ä¸‹è½½å°è¯• {attempt + 1}/{max_retries}: {url}")
                
                response = session.get(url, stream=True, headers=headers, timeout=60)
                response.raise_for_status()
                
                with open(file_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                
                print(f"âœ“ ä¸‹è½½æˆåŠŸ: {file_path}")
                return True
                
            except Exception as e:
                print(f"âœ— ä¸‹è½½å¤±è´¥ (å°è¯• {attempt + 1}): {e}")
                if attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 2  # é€’å¢ç­‰å¾…æ—¶é—´
                    print(f"ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                else:
                    raise Exception(f"ä¸‹è½½å¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡: {e}")
        
        return False

    def download_and_apply_update(self, progress_callback=None):
        """Downloads and applies the latest update with enhanced network robustness."""
        repo_owner = self.config.get('github_owner')
        repo_name = self.config.get('github_repo')
        if not repo_owner or not repo_name:
            print("GitHub repository owner or name not configured.")
            return False

        api_url = f"https://api.github.com/repos/{repo_owner}/{repo_name}/releases/latest"
        backup_dir = None
        temp_dir = None
        download_path = None
        
        try:
            # é…ç½®ç½‘ç»œè¯·æ±‚å‚æ•°
            session = requests.Session()
            session.trust_env = False
            session.proxies = {}
            headers = {
                'User-Agent': 'MJ-Translator-Update-Checker/1.0',
                'Accept': 'application/vnd.github.v3+json'
            }
            
            # Get latest release info
            if progress_callback:
                progress_callback(5, "è·å–æ›´æ–°ä¿¡æ¯", "æ­£åœ¨è¿æ¥GitHub API...")
            response = session.get(api_url, headers=headers, timeout=30, proxies={})
            response.raise_for_status()
            latest_release = response.json()
            
            # Get download URL with fallback
            if progress_callback:
                progress_callback(10, "è·å–ä¸‹è½½é“¾æ¥", "æ­£åœ¨è§£æä¸‹è½½åœ°å€...")
            
            download_url, file_name, file_size = self._get_download_url_with_fallback(latest_release)
            print(f"é€‰æ‹©çš„ä¸‹è½½URL: {download_url}")
            print(f"æ–‡ä»¶å: {file_name}")
            if file_size > 0:
                print(f"æ–‡ä»¶å¤§å°: {file_size / 1024 / 1024:.2f} MB")
            
            # Create backup directory
            project_root = Path(__file__).parent.parent
            backup_dir = project_root / "backup_before_update"
            backup_dir.mkdir(exist_ok=True)
            
            if progress_callback:
                progress_callback(20, "åˆ›å»ºå¤‡ä»½", "æ­£åœ¨å¤‡ä»½å½“å‰ç‰ˆæœ¬...")
            else:
                print("Creating backup of current version...")
            self._backup_current_version(backup_dir)
            
            # Download the update with retry mechanism
            if progress_callback:
                progress_callback(30, "ä¸‹è½½æ›´æ–°", f"æ­£åœ¨ä¸‹è½½ {file_name}...")
            else:
                print(f"Downloading {file_name} from {download_url}...")
            
            temp_dir = tempfile.mkdtemp()
            download_path = os.path.join(temp_dir, file_name)
            self._download_with_retry(download_url, download_path, headers)
            
            if progress_callback:
                progress_callback(70, "ä¸‹è½½å®Œæˆ", f"æ–‡ä»¶å·²ä¸‹è½½åˆ° {download_path}")
            else:
                print(f"Downloaded update to {download_path}")
            
            # Extract and apply update
            if progress_callback:
                progress_callback(80, "åº”ç”¨æ›´æ–°", "æ­£åœ¨è§£å‹å’Œåº”ç”¨æ›´æ–°...")
            else:
                print("Extracting and applying update...")
            self._extract_and_apply_update(download_path, project_root)
            
            if progress_callback:
                progress_callback(95, "æ¸…ç†æ–‡ä»¶", "æ­£åœ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
            else:
                print("Update applied successfully!")
            
            # Clean up
            self._cleanup_after_update(backup_dir, temp_dir)
            
            if progress_callback:
                progress_callback(100, "æ›´æ–°å®Œæˆ", "æ›´æ–°å·²æˆåŠŸåº”ç”¨ï¼")
            else:
                print("Update completed successfully!")
            
            return True
            
        except Exception as e:
            if progress_callback:
                progress_callback(100, "æ›´æ–°å¤±è´¥", f"æ›´æ–°è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
            else:
                print(f"Error during update: {e}")
                print("Rolling back to previous version...")
            
            if backup_dir and backup_dir.exists():
                self._rollback_update(backup_dir)
                print("Rollback completed.")
            
            # å¦‚æœæ˜¯ç½‘ç»œç›¸å…³é”™è¯¯ï¼Œæ˜¾ç¤ºæ‰‹åŠ¨æ›´æ–°æŒ‡å—
            error_str = str(e).lower()
            if any(keyword in error_str for keyword in ['connection', 'timeout', 'dns', 'network', 'github.com', 'codeload']):
                print("\næ£€æµ‹åˆ°ç½‘ç»œè¿æ¥é—®é¢˜ï¼Œåˆ‡æ¢åˆ°ç¦»çº¿æ¨¡å¼...")
                # å°è¯•ä»ç¼“å­˜è·å–æ›´æ–°ä¿¡æ¯
                cached_update = self._check_offline_update()
                if cached_update and cached_update[0]:  # å¦‚æœæœ‰ç¼“å­˜çš„æ›´æ–°ä¿¡æ¯
                    self.show_manual_update_guide()
                else:
                    print("\nğŸ’¡ ç½‘ç»œé—®é¢˜è§£å†³å»ºè®®:")
                    print("  - æ›´æ¢DNSæœåŠ¡å™¨ï¼ˆ8.8.8.8, 114.114.114.114ï¼‰")
                    print("  - æ£€æŸ¥é˜²ç«å¢™å’Œæ€æ¯’è½¯ä»¶è®¾ç½®")
                    print("  - å°è¯•ä½¿ç”¨ç§»åŠ¨çƒ­ç‚¹ç½‘ç»œ")
                    print("  - è®¿é—® https://github.com/yuanxiao9889/MJ-translate/releases æ‰‹åŠ¨ä¸‹è½½")
            
            # Clean up temp files
            if temp_dir and os.path.exists(temp_dir):
                shutil.rmtree(temp_dir, ignore_errors=True)
                
            return False
    
    def _backup_current_version(self, backup_dir):
        """Creates a backup of critical files before update."""
        project_root = Path(__file__).parent.parent
        
        # Files and directories to backup
        backup_items = [
            'main.py',
            'services/',
            'views/',
            'config.json',
            'requirements.txt'
        ]
        
        for item in backup_items:
            source_path = project_root / item
            if source_path.exists():
                dest_path = backup_dir / item
                if source_path.is_file():
                    dest_path.parent.mkdir(parents=True, exist_ok=True)
                    shutil.copy2(source_path, dest_path)
                elif source_path.is_dir():
                    if dest_path.exists():
                        shutil.rmtree(dest_path)
                    shutil.copytree(source_path, dest_path)
    
    def _extract_and_apply_update(self, zip_path, project_root):
        """Extracts the update zip and applies it to the project."""
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            # Extract to temporary directory first
            temp_extract_dir = tempfile.mkdtemp()
            zip_ref.extractall(temp_extract_dir)
            
            # Find the actual project directory in the extracted files
            extracted_items = os.listdir(temp_extract_dir)
            if len(extracted_items) == 1 and os.path.isdir(os.path.join(temp_extract_dir, extracted_items[0])):
                # If there's a single directory, use that as the source
                source_dir = os.path.join(temp_extract_dir, extracted_items[0])
            else:
                # Otherwise, use the temp directory directly
                source_dir = temp_extract_dir
            
            # Copy files from extracted directory to project root
            skip_files = {"config.json"}
            skip_dirs = {"backup_before_update", "manual_update", ".update_cache"}
            for item in os.listdir(source_dir):
                # è·³è¿‡ä¸åº”è¦†ç›–çš„æ–‡ä»¶/ç›®å½•
                if item in skip_files or item in skip_dirs:
                    continue
                source_item = os.path.join(source_dir, item)
                dest_item = project_root / item
                
                if os.path.isfile(source_item):
                    shutil.copy2(source_item, dest_item)
                elif os.path.isdir(source_item):
                    if dest_item.exists():
                        shutil.rmtree(dest_item)
                    shutil.copytree(source_item, dest_item)
            
            # Clean up temp extraction directory
            shutil.rmtree(temp_extract_dir, ignore_errors=True)
    
    def _rollback_update(self, backup_dir):
        """Rolls back to the backed up version."""
        project_root = Path(__file__).parent.parent
        
        for item in backup_dir.iterdir():
            dest_path = project_root / item.name
            
            if item.is_file():
                shutil.copy2(item, dest_path)
            elif item.is_dir():
                if dest_path.exists():
                    shutil.rmtree(dest_path)
                shutil.copytree(item, dest_path)
    
    def _cleanup_after_update(self, backup_dir, temp_dir):
        """Cleans up temporary files after successful update."""
        # Remove backup directory
        if backup_dir and backup_dir.exists():
            shutil.rmtree(backup_dir, ignore_errors=True)
        
        # Remove temp directory
        if temp_dir and os.path.exists(temp_dir):
            shutil.rmtree(temp_dir, ignore_errors=True)
    
    def _save_release_info(self, release_data):
        """ä¿å­˜å‘å¸ƒä¿¡æ¯åˆ°æœ¬åœ°ç¼“å­˜"""
        try:
            cache_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), '.update_cache')
            os.makedirs(cache_dir, exist_ok=True)
            
            cache_file = os.path.join(cache_dir, 'latest_release.json')
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(release_data, f, ensure_ascii=False, indent=2)
            
            print(f"å‘å¸ƒä¿¡æ¯å·²ç¼“å­˜åˆ°: {cache_file}")
        except Exception as e:
            print(f"è­¦å‘Š: æ— æ³•ç¼“å­˜å‘å¸ƒä¿¡æ¯: {e}")
    
    def _check_offline_update(self):
        """æ£€æŸ¥ç¦»çº¿æ›´æ–°"""
        try:
            cache_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), '.update_cache')
            cache_file = os.path.join(cache_dir, 'latest_release.json')
            
            if os.path.exists(cache_file):
                with open(cache_file, 'r', encoding='utf-8') as f:
                    release_data = json.load(f)
                
                latest_version = release_data.get('tag_name', '').lstrip('v')
                release_notes = release_data.get('body', '')
                
                if self.is_new_version_available(latest_version):
                    print(f"ä»ç¼“å­˜ä¸­å‘ç°æ–°ç‰ˆæœ¬: {latest_version}")
                    self.offline_mode = True
                    self.manual_download_info = self._prepare_manual_download_info(release_data)
                    return latest_version, release_notes
            
            return None, None
        except Exception as e:
            print(f"ç¦»çº¿æ£€æŸ¥å¤±è´¥: {e}")
            return None, None
    
    def _prepare_manual_download_info(self, release_data):
        """å‡†å¤‡æ‰‹åŠ¨ä¸‹è½½ä¿¡æ¯"""
        repo_owner = self.config.get('github_owner')
        repo_name = self.config.get('github_repo')
        tag_name = release_data.get('tag_name', 'latest')
        
        download_info = {
            'version': tag_name,
            'release_url': release_data.get('html_url', ''),
            'download_urls': [
                f"https://github.com/{repo_owner}/{repo_name}/archive/refs/tags/{tag_name}.zip"
            ],
            'manual_steps': [
                f"1. è®¿é—®å‘å¸ƒé¡µé¢: {release_data.get('html_url', '')}",
                f"2. ä¸‹è½½æºä»£ç ZIPæ–‡ä»¶",
                f"3. å°†ä¸‹è½½çš„æ–‡ä»¶æ”¾ç½®åˆ°: {os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'manual_update')}",
                f"4. é‡æ–°è¿è¡Œæ›´æ–°ç¨‹åº"
            ]
        }
        
        return download_info
    
    def show_manual_update_guide(self):
        """æ˜¾ç¤ºæ‰‹åŠ¨æ›´æ–°æŒ‡å—"""
        if not self.manual_download_info:
            print("âŒ æ— æ‰‹åŠ¨æ›´æ–°ä¿¡æ¯å¯æ˜¾ç¤º")
            return
        
        print("\n" + "=" * 60)
        print("ğŸ”„ æ‰‹åŠ¨æ›´æ–°æŒ‡å—")
        print("=" * 60)
        
        print(f"æ£€æµ‹åˆ°æ–°ç‰ˆæœ¬: {self.manual_download_info['version']}")
        print("ç”±äºç½‘ç»œé—®é¢˜ï¼Œæ— æ³•è‡ªåŠ¨ä¸‹è½½æ›´æ–°ã€‚")
        print("\nè¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ‰‹åŠ¨æ›´æ–°:")
        
        for step in self.manual_download_info['manual_steps']:
            print(f"  {step}")
        
        print("\nå¯ç”¨ä¸‹è½½é“¾æ¥:")
        for i, url in enumerate(self.manual_download_info['download_urls'], 1):
            print(f"  {i}. {url}")
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ‰‹åŠ¨ä¸‹è½½çš„æ–‡ä»¶
        manual_update_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'manual_update')
        if os.path.exists(manual_update_dir):
            zip_files = [f for f in os.listdir(manual_update_dir) if f.endswith('.zip')]
            if zip_files:
                print(f"\nâœ“ å‘ç°æ‰‹åŠ¨ä¸‹è½½çš„æ–‡ä»¶: {zip_files}")
                print("é‡æ–°è¿è¡Œæ›´æ–°ç¨‹åºä»¥åº”ç”¨è¿™äº›æ–‡ä»¶ã€‚")
        else:
            print(f"\nğŸ“ è¯·åˆ›å»ºç›®å½•å¹¶æ”¾ç½®ä¸‹è½½æ–‡ä»¶: {manual_update_dir}")
        
        print("\nğŸ’¡ ç½‘ç»œé—®é¢˜è§£å†³å»ºè®®:")
        print("  - æ›´æ¢DNSæœåŠ¡å™¨ï¼ˆ8.8.8.8, 114.114.114.114ï¼‰")
        print("  - æ£€æŸ¥é˜²ç«å¢™å’Œæ€æ¯’è½¯ä»¶è®¾ç½®")
        print("  - å°è¯•ä½¿ç”¨ç§»åŠ¨çƒ­ç‚¹ç½‘ç»œ")
        print("  - å¦‚åœ¨ä¼ä¸šç½‘ç»œä¸­ï¼Œè”ç³»ç½‘ç»œç®¡ç†å‘˜")