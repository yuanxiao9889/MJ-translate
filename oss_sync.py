import os
import json
import hashlib
import oss2
from PIL import Image
import io
from typing import Optional, Tuple

# å¯¼å…¥å‡­æ®ç®¡ç†å™¨
from services.credentials_manager import CredentialsManager
from services.logger import logger

try:
    from tkinter import messagebox
except ImportError:
    messagebox = None

LOCAL_JSON = "tags.json"
REMOTE_JSON = "tags.json"
LOCAL_IMG_DIR = "images"
REMOTE_IMG_PREFIX = "images/"

# æ–°å¢ï¼šæ”¶è—å¤¹å’Œå†å²è®°å½•æ–‡ä»¶é…ç½®
FAVORITES_FILE = "favorites.txt"
REMOTE_FAVORITES_FILE = "favorites.txt"
HISTORY_FILE = "history.json"
REMOTE_HISTORY_FILE = "history.json"

# å…¨å±€å˜é‡
_bucket = None
_cred_manager = None

def get_oss_credentials() -> Optional[Tuple[str, str, str, str]]:
    """è·å–OSSå‡­æ®
    
    Returns:
        (access_key_id, access_key_secret, endpoint, bucket_name) æˆ– None
    """
    global _cred_manager
    if _cred_manager is None:
        _cred_manager = CredentialsManager()
    
    # è·å–å¯ç”¨çš„OSSå‡­æ®
    credentials = _cred_manager.get_credentials()
    oss_creds = credentials.get("aliyun_oss", [])
    
    # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªå¯ç”¨çš„å‡­æ®
    for cred in oss_creds:
        if not cred.get("disabled", False):
            access_key_id = cred.get("access_key_id")
            access_key_secret = cred.get("access_key_secret")
            region = cred.get("region", "oss-cn-shenzhen.aliyuncs.com")
            bucket_name = cred.get("bucket_name")
            
            if access_key_id and access_key_secret and bucket_name:
                # ç¡®ä¿endpointæ ¼å¼æ­£ç¡®
                if not region.startswith("https://"):
                    endpoint = f"https://{region}"
                else:
                    endpoint = region
                return access_key_id, access_key_secret, endpoint, bucket_name
    
    return None

def get_oss_bucket():
    """è·å–OSS bucketå¯¹è±¡
    
    Returns:
        oss2.Bucketå¯¹è±¡æˆ–None
    """
    global _bucket
    
    # å¦‚æœå·²ç»æœ‰bucketå¯¹è±¡ï¼Œç›´æ¥è¿”å›
    if _bucket is not None:
        return _bucket
    
    # è·å–å‡­æ®
    cred_info = get_oss_credentials()
    if cred_info is None:
        return None
    
    access_key_id, access_key_secret, endpoint, bucket_name = cred_info
    
    try:
        auth = oss2.Auth(access_key_id, access_key_secret)
        _bucket = oss2.Bucket(auth, endpoint, bucket_name)
        return _bucket
    except Exception as e:
        logger.error(f"åˆ›å»ºOSS bucketå¤±è´¥: {e}")
        return None

def prompt_for_oss_credentials():
    """æç¤ºç”¨æˆ·æä¾›OSSå‡­æ®"""
    if messagebox:
        result = messagebox.askyesno(
            "ç¼ºå°‘OSSå‡­æ®",
            "æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„é˜¿é‡Œäº‘OSSå‡­æ®ã€‚\n\næ˜¯å¦è¦æ‰“å¼€å‡­æ®ç®¡ç†çª—å£æ·»åŠ OSSå‡­æ®ï¼Ÿ"
        )
        if result:
            # è¿™é‡Œå¯ä»¥è§¦å‘æ‰“å¼€å‡­æ®ç®¡ç†çª—å£çš„é€»è¾‘
            # ç”±äºå¾ªç¯å¯¼å…¥é—®é¢˜ï¼Œè¿™é‡Œåªæ˜¯æç¤º
            messagebox.showinfo(
                "æç¤º",
                "è¯·é€šè¿‡ä¸»ç•Œé¢çš„'è®¾ç½®' -> 'APIä¸å­˜å‚¨ç®¡ç†'èœå•æ·»åŠ é˜¿é‡Œäº‘OSSå‡­æ®ã€‚"
            )
    else:
        print("é”™è¯¯ï¼šæ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„é˜¿é‡Œäº‘OSSå‡­æ®ï¼Œè¯·é€šè¿‡å‡­æ®ç®¡ç†åŠŸèƒ½æ·»åŠ ã€‚")

# ä¸ºäº†å‘åå…¼å®¹ï¼Œä¿ç•™bucketå˜é‡
bucket = None

# å·¥å…·å‡½æ•°
def md5_of_file(path):
    with open(path, "rb") as f:
        return hashlib.md5(f.read()).hexdigest()

def md5_of_bytes(data):
    return hashlib.md5(data).hexdigest()

# ========== ä¸Šä¼ éƒ¨åˆ† ==========
def upload_all(status_var=None, root=None):
    # è·å–OSS bucket
    bucket = get_oss_bucket()
    if bucket is None:
        print("é”™è¯¯ï¼šæ— æ³•è·å–OSSå‡­æ®ï¼Œè¯·å…ˆé…ç½®é˜¿é‡Œäº‘OSSå‡­æ®")
        prompt_for_oss_credentials()
        if status_var: status_var.set("OSSå‡­æ®æœªé…ç½®")
        return False
    
    files_to_upload = [
        (LOCAL_JSON, REMOTE_JSON, "tags.json"),
        (FAVORITES_FILE, REMOTE_FAVORITES_FILE, "æ”¶è—å¤¹"),
        (HISTORY_FILE, REMOTE_HISTORY_FILE, "å†å²è®°å½•")
    ]
    
    total_files = len([f for f, _, _ in files_to_upload if os.path.exists(f)])
    current_file = 0
    
    for local_file, remote_file, display_name in files_to_upload:
        if not os.path.exists(local_file):
            print(f"âš ï¸ æœ¬åœ°{display_name}æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            continue
            
        current_file += 1
        
        # JSONæ–‡ä»¶æ ¼å¼æ ¡éªŒ
        if local_file.endswith('.json'):
            try:
                with open(local_file, 'r', encoding='utf-8') as f:
                    json.load(f)
                print(f"âœ… æœ¬åœ°{display_name}æ ¡éªŒé€šè¿‡ï¼Œå‡†å¤‡ä¸Šä¼ ")
            except Exception as e:
                print(f"âŒ æœ¬åœ°{display_name}æ ¼å¼é”™è¯¯ï¼Œä¸Šä¼ ä¸­æ­¢ï¼", e)
                if status_var: status_var.set(f"{display_name}æ ¼å¼é”™è¯¯ï¼Œä¸Šä¼ ä¸­æ­¢")
                return False
        
        def progress_callback(consumed_bytes, total_bytes, name=display_name, file_idx=current_file, total=total_files):
            percent = int(100 * consumed_bytes / total_bytes) if total_bytes > 0 else 100
            if status_var:
                status_var.set(f"{name}({file_idx}/{total}) ä¸Šä¼ ä¸­ {percent}%")
            if root:
                root.update_idletasks()
        
        try:
            bucket.put_object_from_file(remote_file, local_file, progress_callback=progress_callback)
            print(f"âœ… å·²ä¸Šä¼ {display_name}")
            if status_var: status_var.set(f"{display_name}ä¸Šä¼ å®Œæˆ")
        except Exception as e:
            print(f"âŒ ä¸Šä¼ {display_name}å¤±è´¥ï¼š", e)
            if status_var: status_var.set(f"{display_name}ä¸Šä¼ å¤±è´¥")
            return False

    # ä¸Šä¼ å›¾ç‰‡ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
    uploaded_keys = set()
    if os.path.isdir(LOCAL_IMG_DIR):
        img_files = [f for f in os.listdir(LOCAL_IMG_DIR) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))]
        total = len(img_files)
        for idx, filename in enumerate(img_files):
            local_path = os.path.join(LOCAL_IMG_DIR, filename)
            try:
                with open(local_path, "rb") as f:
                    img_bytes = f.read()
                Image.open(io.BytesIO(img_bytes)).verify()
            except Exception as e:
                print(f"âš ï¸ è·³è¿‡åå›¾ç‰‡ï¼š{filename}ï¼Œé”™è¯¯ï¼š{e}")
                continue
            remote_key = REMOTE_IMG_PREFIX + filename
            uploaded_keys.add(remote_key)
            # å¢é‡æ£€æŸ¥
            try:
                head = bucket.head_object(remote_key)
                cloud_md5 = head.etag
                local_md5 = md5_of_bytes(img_bytes)
                if cloud_md5 == local_md5:
                    continue
            except oss2.exceptions.NoSuchKey:
                pass
            def img_progress(consumed_bytes, total_bytes, idx=idx, total=total, filename=filename):
                percent = int(100 * consumed_bytes / total_bytes)
                if status_var:
                    status_var.set(f"å›¾ç‰‡({idx+1}/{total}) {filename} ä¸Šä¼ ä¸­ {percent}%")
                if root:
                    root.update_idletasks()
            bucket.put_object(remote_key, img_bytes, progress_callback=img_progress)
            print(f"âœ… å·²ä¸Šä¼ å›¾ç‰‡ï¼š{filename}")
        if status_var: status_var.set("å›¾ç‰‡ä¸Šä¼ å®Œæˆ")

    # åˆ é™¤å¤šä½™å›¾ç‰‡
    server_objs = [obj.key for obj in oss2.ObjectIterator(bucket, prefix=REMOTE_IMG_PREFIX)]
    deleted = 0
    for key in server_objs:
        if key not in uploaded_keys and key != REMOTE_IMG_PREFIX:
            bucket.delete_object(key)
            print(f"ğŸ—‘ï¸ å·²åˆ é™¤äº‘ç«¯å¤šä½™å›¾ç‰‡ï¼š{key}")
            deleted += 1
    if deleted > 0:
        print(f"âœ… åŒæ­¥åˆ é™¤{deleted}ä¸ªäº‘ç«¯å¤šä½™å›¾ç‰‡")

# ========== ä¸‹è½½éƒ¨åˆ† ==========
def download_all_simple():
    """ä¸‹è½½OSSä¸Šçš„æ‰€æœ‰æ–‡ä»¶åˆ°æœ¬åœ°ï¼ˆç®€å•ç‰ˆæœ¬ï¼‰"""
    print("å¼€å§‹ä»OSSä¸‹è½½æ‰€æœ‰æ–‡ä»¶...")
    
    # è·å–OSS bucket
    bucket = get_oss_bucket()
    if bucket is None:
        print("é”™è¯¯ï¼šæ— æ³•è·å–OSSå‡­æ®ï¼Œè¯·å…ˆé…ç½®é˜¿é‡Œäº‘OSSå‡­æ®")
        prompt_for_oss_credentials()
        return False
    
    # 1. ä¸‹è½½ tags.json
    try:
        bucket.get_object_to_file(REMOTE_JSON, LOCAL_JSON)
        print(f"âœ“ ä¸‹è½½ {REMOTE_JSON} -> {LOCAL_JSON}")
    except oss2.exceptions.NoSuchKey:
        print(f"âœ— è¿œç¨‹æ–‡ä»¶ {REMOTE_JSON} ä¸å­˜åœ¨")
    except Exception as e:
        print(f"âœ— ä¸‹è½½ {REMOTE_JSON} å¤±è´¥: {e}")
    
    # 2. ä¸‹è½½ images/ ç›®å½•ä¸‹çš„æ‰€æœ‰å›¾ç‰‡
    # ç¡®ä¿æœ¬åœ°ç›®å½•å­˜åœ¨
    if not os.path.exists(LOCAL_IMG_DIR):
        os.makedirs(LOCAL_IMG_DIR)
    
    try:
        # åˆ—å‡ºè¿œç¨‹images/ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
        for obj in oss2.ObjectIterator(bucket, prefix=REMOTE_IMG_PREFIX):
            if obj.key != REMOTE_IMG_PREFIX:  # è·³è¿‡ç›®å½•æœ¬èº«
                filename = obj.key[len(REMOTE_IMG_PREFIX):]  # å»æ‰å‰ç¼€
                local_path = os.path.join(LOCAL_IMG_DIR, filename)
                try:
                    bucket.get_object_to_file(obj.key, local_path)
                    print(f"âœ“ ä¸‹è½½ {obj.key} -> {local_path}")
                except Exception as e:
                    print(f"âœ— ä¸‹è½½ {obj.key} å¤±è´¥: {e}")
    except Exception as e:
        print(f"âœ— åˆ—å‡ºè¿œç¨‹å›¾ç‰‡å¤±è´¥: {e}")
    
    # 3. ä¸‹è½½æ”¶è—å¤¹æ–‡ä»¶
    try:
        bucket.get_object_to_file(REMOTE_FAVORITES_FILE, FAVORITES_FILE)
        print(f"âœ“ ä¸‹è½½ {REMOTE_FAVORITES_FILE} -> {FAVORITES_FILE}")
    except oss2.exceptions.NoSuchKey:
        print(f"âœ— è¿œç¨‹æ–‡ä»¶ {REMOTE_FAVORITES_FILE} ä¸å­˜åœ¨")
    except Exception as e:
        print(f"âœ— ä¸‹è½½ {REMOTE_FAVORITES_FILE} å¤±è´¥: {e}")
    
    # 4. ä¸‹è½½å†å²è®°å½•æ–‡ä»¶
    try:
        bucket.get_object_to_file(REMOTE_HISTORY_FILE, HISTORY_FILE)
        print(f"âœ“ ä¸‹è½½ {REMOTE_HISTORY_FILE} -> {HISTORY_FILE}")
    except oss2.exceptions.NoSuchKey:
        print(f"âœ— è¿œç¨‹æ–‡ä»¶ {REMOTE_HISTORY_FILE} ä¸å­˜åœ¨")
    except Exception as e:
        print(f"âœ— ä¸‹è½½ {REMOTE_HISTORY_FILE} å¤±è´¥: {e}")
    
    print("ä¸‹è½½å®Œæˆï¼")
    return True

def download_all(status_var=None, root=None):
    # è·å–OSS bucket
    bucket = get_oss_bucket()
    if bucket is None:
        print("é”™è¯¯ï¼šæ— æ³•è·å–OSSå‡­æ®ï¼Œè¯·å…ˆé…ç½®é˜¿é‡Œäº‘OSSå‡­æ®")
        prompt_for_oss_credentials()
        if status_var: status_var.set("OSSå‡­æ®æœªé…ç½®")
        return {"head": {}, "tail": {}}
    
    files_to_download = [
        (REMOTE_JSON, LOCAL_JSON, "tags.json"),
        (REMOTE_FAVORITES_FILE, FAVORITES_FILE, "æ”¶è—å¤¹"),
        (REMOTE_HISTORY_FILE, HISTORY_FILE, "å†å²è®°å½•")
    ]
    
    data = {"head": {}, "tail": {}}
    
    # ä¸‹è½½å¼€å§‹æç¤º
    if status_var:
        status_var.set("ä¸‹è½½ä¸­...")
    if root:
        root.update_idletasks()

    # ä¸‹è½½å„ä¸ªæ–‡ä»¶
    for remote_file, local_file, display_name in files_to_download:
        try:
            print(f"ğŸ“¥ ä¸‹è½½{display_name}")
            result = bucket.get_object(remote_file)
            raw = result.read()
            
            # åˆ›å»ºå¤‡ä»½
            backup_file = local_file + ".backup"
            if os.path.exists(local_file):
                import shutil
                shutil.copy2(local_file, backup_file)
            
            with open(local_file, 'wb') as f:
                f.write(raw)
                
            # JSONæ–‡ä»¶æ ¼å¼æ ¡éªŒ
            if local_file.endswith('.json'):
                try:
                    loaded_data = json.loads(raw.decode("utf-8"))
                    if display_name == "tags.json":
                        data = loaded_data
                    print(f"âœ… {display_name}å¥åº·")
                except Exception as e:
                    print(f"âŒ {display_name}æ ¼å¼é”™è¯¯", e)
                    # æ¢å¤å¤‡ä»½
                    if os.path.exists(backup_file):
                        shutil.copy2(backup_file, local_file)
                    print(f"âš ï¸ å·²æ¢å¤{display_name}å¤‡ä»½æ–‡ä»¶")
            else:
                print(f"âœ… {display_name}ä¸‹è½½å®Œæˆ")
                
        except oss2.exceptions.NoSuchKey:
            print(f"âš ï¸ äº‘ç«¯{display_name}ä¸å­˜åœ¨ï¼Œè·³è¿‡")
        except Exception as e:
            print(f"âŒ ä¸‹è½½{display_name}å¤±è´¥", e)
            if status_var:
                status_var.set(f"{display_name}ä¸‹è½½å¤±è´¥")

    # ä¸‹è½½å›¾ç‰‡ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
    os.makedirs(LOCAL_IMG_DIR, exist_ok=True)
    total = 0
    bad_img = 0
    for obj in oss2.ObjectIterator(bucket, prefix=REMOTE_IMG_PREFIX):
        fname = obj.key[len(REMOTE_IMG_PREFIX):]
        if not fname:
            continue
        local_path = os.path.join(LOCAL_IMG_DIR, fname)
        try:
            result = bucket.get_object(obj.key)
            img_data = result.read()
            with open(local_path, "wb") as f:
                f.write(img_data)
            try:
                Image.open(io.BytesIO(img_data)).verify()
                print(f"âœ… ä¸‹è½½å›¾ç‰‡ï¼š{fname}")
            except Exception as e:
                print(f"âš ï¸ å›¾ç‰‡æŸåæˆ–æ— æ³•æ‰“å¼€ï¼š{fname}")
                bad_img += 1
        except Exception as e:
            print(f"âŒ ä¸‹è½½å›¾ç‰‡å¤±è´¥ï¼š{fname}", e)
        total += 1

    # ä¸‹è½½å®Œæˆæç¤º
    if status_var:
        status_var.set("ä¸‹è½½å®Œæˆ")
    print(f"ğŸ‰ ä¸‹è½½å®Œæ¯•ï¼Œå…±{total}å¼ å›¾ç‰‡")
    return data

# ========== å°è£…åŒæ­¥è°ƒç”¨ ==========
def save_tags_with_sync(tags_data):
    with open(LOCAL_JSON, 'w', encoding='utf-8') as f:
        json.dump(tags_data, f, ensure_ascii=False, indent=2)
    upload_all()

def save_favorites_with_sync(favorites_data):
    with open(FAVORITES_FILE, 'w', encoding='utf-8') as f:
        json.dump(favorites_data, f, ensure_ascii=False, indent=2)
    upload_all()

def save_history_with_sync(history_data):
    with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
        json.dump(history_data, f, ensure_ascii=False, indent=2)
    upload_all()

def load_tags_with_sync():
    return download_all()

# ========== æ–°å¢ï¼šå•ç‹¬åŒæ­¥å‡½æ•° ==========
def sync_favorites_only(status_var=None, root=None):
    """ä»…åŒæ­¥æ”¶è—å¤¹"""
    # è·å–OSS bucket
    bucket = get_oss_bucket()
    if bucket is None:
        print("é”™è¯¯ï¼šæ— æ³•è·å–OSSå‡­æ®ï¼Œè¯·å…ˆé…ç½®é˜¿é‡Œäº‘OSSå‡­æ®")
        prompt_for_oss_credentials()
        if status_var: status_var.set("OSSå‡­æ®æœªé…ç½®")
        return False
    
    try:
        if status_var:
            status_var.set("åŒæ­¥æ”¶è—å¤¹ä¸­...")
        if root:
            root.update_idletasks()
            
        # ä¸‹è½½æ”¶è—å¤¹
        try:
            result = bucket.get_object(REMOTE_FAVORITES_FILE)
            raw = result.read()
            with open(FAVORITES_FILE, 'wb') as f:
                f.write(raw)
            print("âœ… æ”¶è—å¤¹åŒæ­¥å®Œæˆ")
            if status_var:
                status_var.set("æ”¶è—å¤¹åŒæ­¥å®Œæˆ")
            return True
        except oss2.exceptions.NoSuchKey:
            print("âš ï¸ äº‘ç«¯æ”¶è—å¤¹ä¸å­˜åœ¨")
            if status_var:
                status_var.set("äº‘ç«¯æ”¶è—å¤¹ä¸å­˜åœ¨")
            return False
    except Exception as e:
        print("âŒ æ”¶è—å¤¹åŒæ­¥å¤±è´¥", e)
        if status_var:
            status_var.set("æ”¶è—å¤¹åŒæ­¥å¤±è´¥")
        return False

def sync_history_only(status_var=None, root=None):
    """ä»…åŒæ­¥å†å²è®°å½•"""
    # è·å–OSS bucket
    bucket = get_oss_bucket()
    if bucket is None:
        print("é”™è¯¯ï¼šæ— æ³•è·å–OSSå‡­æ®ï¼Œè¯·å…ˆé…ç½®é˜¿é‡Œäº‘OSSå‡­æ®")
        prompt_for_oss_credentials()
        if status_var: status_var.set("OSSå‡­æ®æœªé…ç½®")
        return False
    
    try:
        if status_var:
            status_var.set("åŒæ­¥å†å²è®°å½•ä¸­...")
        if root:
            root.update_idletasks()
            
        # ä¸‹è½½å†å²è®°å½•
        try:
            result = bucket.get_object(REMOTE_HISTORY_FILE)
            raw = result.read()
            with open(HISTORY_FILE, 'wb') as f:
                f.write(raw)
            print("âœ… å†å²è®°å½•åŒæ­¥å®Œæˆ")
            if status_var:
                status_var.set("å†å²è®°å½•åŒæ­¥å®Œæˆ")
            return True
        except oss2.exceptions.NoSuchKey:
            print("âš ï¸ äº‘ç«¯å†å²è®°å½•ä¸å­˜åœ¨")
            if status_var:
                status_var.set("äº‘ç«¯å†å²è®°å½•ä¸å­˜åœ¨")
            return False
    except Exception as e:
        print("âŒ å†å²è®°å½•åŒæ­¥å¤±è´¥", e)
        if status_var:
            status_var.set("å†å²è®°å½•åŒæ­¥å¤±è´¥")
        return False

def smart_sync():
    """æ™ºèƒ½åŒæ­¥ï¼šæ¯”è¾ƒæœ¬åœ°å’Œè¿œç¨‹çš„ tags.jsonï¼Œåˆå¹¶å·®å¼‚"""
    print("å¼€å§‹æ™ºèƒ½åŒæ­¥...")
    
    # è·å–OSS bucket
    bucket = get_oss_bucket()
    if bucket is None:
        print("é”™è¯¯ï¼šæ— æ³•è·å–OSSå‡­æ®ï¼Œè¯·å…ˆé…ç½®é˜¿é‡Œäº‘OSSå‡­æ®")
        prompt_for_oss_credentials()
        return False
    
    # 1. å…ˆå°è¯•ä¸‹è½½è¿œç¨‹çš„ tags.json
    remote_data = {}
    try:
        # ä¸‹è½½åˆ°ä¸´æ—¶æ–‡ä»¶
        temp_file = "temp_remote_tags.json"
        bucket.get_object_to_file(REMOTE_JSON, temp_file)
        
        with open(temp_file, 'r', encoding='utf-8') as f:
            remote_data = json.load(f)
        
        os.remove(temp_file)  # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        print(f"âœ“ æˆåŠŸè·å–è¿œç¨‹ {REMOTE_JSON}")
    except oss2.exceptions.NoSuchKey:
        print(f"âš ï¸ è¿œç¨‹æ–‡ä»¶ {REMOTE_JSON} ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨æœ¬åœ°æ•°æ®")
        remote_data = {}
    except Exception as e:
        print(f"âœ— è·å–è¿œç¨‹ {REMOTE_JSON} å¤±è´¥: {e}")
        return False
    
    # 2. è¯»å–æœ¬åœ°çš„ tags.json
    local_data = {}
    if os.path.exists(LOCAL_JSON):
        try:
            with open(LOCAL_JSON, 'r', encoding='utf-8') as f:
                local_data = json.load(f)
            print(f"âœ“ æˆåŠŸè¯»å–æœ¬åœ° {LOCAL_JSON}")
        except Exception as e:
            print(f"âœ— è¯»å–æœ¬åœ° {LOCAL_JSON} å¤±è´¥: {e}")
            return False
    else:
        print(f"âš ï¸ æœ¬åœ°æ–‡ä»¶ {LOCAL_JSON} ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨è¿œç¨‹æ•°æ®")
    
    # 3. åˆå¹¶æ•°æ®
    merged_data = merge_tags_data(local_data, remote_data)
    
    # 4. ä¿å­˜åˆå¹¶åçš„æ•°æ®åˆ°æœ¬åœ°
    try:
        with open(LOCAL_JSON, 'w', encoding='utf-8') as f:
            json.dump(merged_data, f, ensure_ascii=False, indent=2)
        print(f"âœ“ ä¿å­˜åˆå¹¶æ•°æ®åˆ°æœ¬åœ° {LOCAL_JSON}")
    except Exception as e:
        print(f"âœ— ä¿å­˜æœ¬åœ° {LOCAL_JSON} å¤±è´¥: {e}")
        return False
    
    # 5. ä¸Šä¼ åˆå¹¶åçš„æ•°æ®åˆ°è¿œç¨‹
    try:
        bucket.put_object_from_file(REMOTE_JSON, LOCAL_JSON)
        print(f"âœ“ ä¸Šä¼ åˆå¹¶æ•°æ®åˆ°è¿œç¨‹ {REMOTE_JSON}")
    except Exception as e:
        print(f"âœ— ä¸Šä¼ åˆ°è¿œç¨‹ {REMOTE_JSON} å¤±è´¥: {e}")
        return False
    
    print("æ™ºèƒ½åŒæ­¥å®Œæˆï¼")
    return True

def merge_tags_data(local_data, remote_data):
    """åˆå¹¶æœ¬åœ°å’Œè¿œç¨‹çš„æ ‡ç­¾æ•°æ®"""
    # ç®€å•çš„åˆå¹¶ç­–ç•¥ï¼šä»¥æœ¬åœ°æ•°æ®ä¸ºä¸»ï¼Œè¡¥å……è¿œç¨‹æ•°æ®ä¸­æœ¬åœ°æ²¡æœ‰çš„éƒ¨åˆ†
    merged = local_data.copy()
    
    # åˆå¹¶ head éƒ¨åˆ†
    if "head" in remote_data:
        if "head" not in merged:
            merged["head"] = {}
        for key, value in remote_data["head"].items():
            if key not in merged["head"]:
                merged["head"][key] = value
    
    # åˆå¹¶ tail éƒ¨åˆ†
    if "tail" in remote_data:
        if "tail" not in merged:
            merged["tail"] = {}
        for key, value in remote_data["tail"].items():
            if key not in merged["tail"]:
                merged["tail"][key] = value
    
    return merged

# ========== å…¥å£æµ‹è¯• ==========
if __name__ == "__main__":
    print("---- ä¸‹è½½äº‘ç«¯æ‰€æœ‰å†…å®¹ ----")
    download_all()
    # print("---- ä¸Šä¼ æ‰€æœ‰å†…å®¹åˆ°äº‘ç«¯ ----")
    # upload_all()
# åœ¨download_allå‡½æ•°ä¸­ï¼Œç¡®ä¿æœ‰å®Œæ•´çš„çŠ¶æ€åé¦ˆ
# å‡½æ•°å·²ç»æ”¯æŒstatus_varå’Œrootå‚æ•°ï¼Œæ— éœ€ä¿®æ”¹
